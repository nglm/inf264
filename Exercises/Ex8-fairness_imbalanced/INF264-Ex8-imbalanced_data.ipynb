{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalanced data\n",
    "\n",
    "In this exercise we will have a look at the problems we may face in case of an imbalanced dataset as well as some of the solutions. \n",
    "\n",
    "The data consist of 2 continuous features ``X1`` and ``X2`` and one binary label ``y``. \n",
    "\n",
    "$y$ could be seen as the result of a medical test the label ``0`` meaning that you are positive (ill) and the label ``1`` means that you are negative (healthy). Generally, in this situation there are much more negative than positive but the positive are somehow more important to detect than negative. \n",
    "\n",
    "\n",
    "We will look at 3 different datasets and for each of them we have 3 different values of the proportion 'nb negative'/'total' (70%, 90% and 99%) \n",
    "\n",
    "## Contents\n",
    "\n",
    "1. Visualizing data\n",
    "2. SVC without preprocessing\n",
    "3. SVC with downsampling\n",
    "4. SVC with upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some useful functions\n",
    "\n",
    "Just run the cell below, there is nothing to add and nothing really interesting to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dfs(verbose=False):\n",
    "    '''\n",
    "    Load and return the 9 csv files as a dictionary of dataframes\n",
    "    '''\n",
    "    dfs = {}\n",
    "    for i in range(3):\n",
    "        for prop in [70, 90, 99]:\n",
    "            df_name = 'df0'+str(i)+'_'+str(prop)\n",
    "            df = pd.read_csv(df_name+'.csv',index_col=0)\n",
    "            \n",
    "            dfs[df_name] = df\n",
    "            if verbose:\n",
    "                print(\"\\n=== \", df_name, \" ===\")\n",
    "                print(\"Value counts:\")\n",
    "                print(df['y'].value_counts())\n",
    "\n",
    "    return dfs\n",
    "\n",
    "\n",
    "def plot_datasets(\n",
    "    dfs,\n",
    "    model=None,\n",
    "    cm = plt.cm.RdBu,\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF']),\n",
    "    figsize=(15, 5),\n",
    "    h=0.2,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot datasets and decision boundaries if a trained model is given\n",
    "    \n",
    "    Inspired by sklearn documentation\n",
    "    \"\"\"\n",
    "    \n",
    "    # iterate over proportions\n",
    "    nb_prop = 3\n",
    "    proportions = [70, 90, 99]\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=nb_prop, figsize=figsize)\n",
    "    for i, df in enumerate(dfs):\n",
    "\n",
    "        X = np.array(df[['X1', 'X2']])\n",
    "        y = np.array(df['y'])\n",
    "\n",
    "        x_min, x_max = X[:,0].min() - .5, X[:,0].max() + .5\n",
    "        y_min, y_max = X[:,1].min() - .5, X[:,1].max() + .5\n",
    "\n",
    "        # ---------------------\n",
    "        # Plot datapoints\n",
    "        # ---------------------\n",
    "        ax[i].scatter(X[:,0], X[:,1], c=y, cmap=cm_bright,\n",
    "                edgecolors='k', alpha = 0.2)\n",
    "        \n",
    "        if model is not None:\n",
    "            # ---------------------\n",
    "            # Plot boundaries\n",
    "            # ---------------------\n",
    "            \n",
    "            # Plot the decision boundary. For that, we will assign a color to each\n",
    "            # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "            xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                                 np.arange(y_min, y_max, h))\n",
    "            Z = model.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "            # Put the result into a color plot\n",
    "            Z = Z.reshape(xx.shape)\n",
    "            ax[i].contourf(xx, yy, Z, cmap=cm, alpha=.2)\n",
    "\n",
    "        title = \"Proportion: \" + str(proportions[i])\n",
    "        ax[i].set_title(title)\n",
    "        ax[i].set_xlim(x_min, x_max)\n",
    "        ax[i].set_ylim(y_min, y_max)\n",
    "        ax[i].set_xlabel(\"X1\")\n",
    "        ax[i].set_ylabel(\"X2\")\n",
    "        ax[i].set_xticks(())\n",
    "        ax[i].set_yticks(())\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing data\n",
    "\n",
    "**QUESTION**\n",
    "\n",
    "Run the cell below and answer the following questions:\n",
    "\n",
    "1. For each dataset, what is the difference between the 3 figures?  \n",
    "2. Are some of the 3 datasets easier/harder to solve from a classification viewpoint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = load_dfs()\n",
    "proportions = [70, 90, 99]\n",
    "datasets = []\n",
    "for i in range(3):\n",
    "    print(\"=============================\")\n",
    "    print(\"======== DATASET \", i, \" ========\")\n",
    "    print(\"=============================\")\n",
    "    dataset = [dfs['df0'+str(i)+'_'+str(prop)] for prop in proportions]\n",
    "    datasets.append(dataset)\n",
    "    plot_datasets(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_val, y_val):\n",
    "    acc = model.score(X_val, y_val)\n",
    "    print(\"Accuracy: %.3f\" %acc)\n",
    "    \n",
    "    preds = model.predict(X_val)\n",
    "    # Proportion of pos and neg in reality \n",
    "    tot_pos = np.count_nonzero(y_val == 1)\n",
    "    tot_neg = np.count_nonzero(y_val == 0)\n",
    "    # Predicted 'pos' but 'neg' in reality\n",
    "    false_pos = np.count_nonzero(np.logical_and(preds != y_val, y_val == 0) )\n",
    "    # Predicted 'neg' but 'pos' in reality\n",
    "    false_neg = np.count_nonzero(np.logical_and(preds != y_val, y_val == 1) )\n",
    "\n",
    "    print('Total predictions:    ', len(y_val))\n",
    "    print('Ratio positive/total:  %.3f' %(tot_pos/len(y_val)))\n",
    "    print(\"False positive:       \", false_pos)\n",
    "    print(\"False negative:       \", false_neg)\n",
    "    print('Ratio of positive that are not detected: %.3f' %(false_neg/tot_pos))\n",
    "    print('Ratio of negative that are not detected: %.3f' %(false_pos/tot_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC with no preprocessing\n",
    "\n",
    "Here we use a SVM with a RBF kernel to classify the data\n",
    "The decision boundaries now appear on the plots\n",
    "\n",
    "**QUESTIONS**\n",
    "\n",
    "Run the code below and answer the following questions:\n",
    "\n",
    "1. Does the accuracy seem good for each dataset and each proportion of negative?\n",
    "2. Does the ratio of false negative seem reasonable for each dataset and each proportion?\n",
    "3. Is the accuracy misleading? For each proportion give the accuracy that a classifier labeling all datapoints to the majority class would get\n",
    "4. Look at dataset 0, does the fact that the data is imbalanced seem to have an influence on the performance? \n",
    "5. Same question but with dataset 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, dataset in enumerate(datasets):\n",
    "    print(\"\\n=============================\")\n",
    "    print(\"======== DATASET \", i, \" ========\")\n",
    "    print(\"=============================\\n\")\n",
    "    for j, df in enumerate(dataset):\n",
    "        print(\"\\n======== proportion: \", proportions[j], \" ========\")\n",
    "        X = np.array(df[['X1', 'X2']])\n",
    "        y = np.array(df['y'])\n",
    "        X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=.5, random_state=42)\n",
    "\n",
    "        model = SVC(gamma='auto')\n",
    "        model.fit(X_train, y_train)\n",
    "        plot_datasets(dataset,model)\n",
    "\n",
    "        evaluate(model, X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC using downsampling\n",
    "\n",
    "**QUESTIONS**\n",
    "\n",
    "1. Write a function ``down_sampling`` that takes as input an imbalanced dataset ``X`` and ``y`` and returns ``X_down, y_down``: a subsample of ``X`` and ``y`` such that only ``tot_pos`` negative elements are kept (on top of all the positive elements); ``tot_pos`` being the total number of ``1`` in ``y``\n",
    "\n",
    "2. Once the function ``down_sampling`` is completed: call it on each of your train datasets in the cell below\n",
    "\n",
    "3. Run the cell below and answer the following questions:\n",
    "\n",
    "  1. Compare visualy the boundaries with and without downsampling. What do you observe?\n",
    "  2. Is there a significant change regarding the accuracy?\n",
    "  3. Same question with the ratio of positive that are not detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def down_sampling(X, y):\n",
    "    \"\"\"\n",
    "    Remove occurences of negative labels\n",
    "    \"\"\"\n",
    "    # Count the total number of positive elements\n",
    "    tot_pos = np.count_nonzero(y==1)\n",
    "    \n",
    "    ... #TODO!\n",
    "    \n",
    "    return(X_down, y_down)\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    print(\"\\n=============================\")\n",
    "    print(\"======== DATASET \", i, \" ========\")\n",
    "    print(\"=============================\\n\")\n",
    "    for j, df in enumerate(dataset):\n",
    "        print(\"\\n======== proportion: \", proportions[j], \" ========\")\n",
    "        X = np.array(df[['X1', 'X2']])\n",
    "        y = np.array(df['y'])   \n",
    "        X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=.5, random_state=42)\n",
    "        X_train, y_train = down_sampling(...) #TODO!\n",
    "\n",
    "        model = SVC(gamma=\"auto\")\n",
    "        model.fit(X_train, y_train)\n",
    "        plot_datasets(dataset,model)\n",
    "\n",
    "        evaluate(model, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC using upsampling\n",
    "\n",
    "**QUESTIONS**\n",
    "\n",
    "\n",
    "1. Write a function ``up_sampling`` that takes as input an imbalanced dataset ``X`` and ``y`` and returns ``X_up, y_up``. ``X_up, y_up`` is generated from ``X`` and ``y`` by repeating occurences of positive datapoints until there are ``tot_neg`` positive elements (on top of all the negative elements); ``tot_neg`` being the total number of ``0`` in ``y``\n",
    "\n",
    "2. Once the function ``up_sampling`` is completed: call it on each of your train datasets in the cell below\n",
    "\n",
    "3. Run the cell below and answer the following questions:\n",
    "\n",
    "  1. Compare visualy the boundaries with downsampling/upsampling and without preprocessing. What do you observe?\n",
    "  2. Is there a significant change regarding the accuracy?\n",
    "  3. Same question with the ratio of positive that are not detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def up_sampling(X, y):\n",
    "    \"\"\"\n",
    "    Add occurences of positive labels\n",
    "    \"\"\"\n",
    "    # Count the total number of negative elements\n",
    "    tot_neg = np.count_nonzero(y==0)\n",
    "    \n",
    "    ... #TODO!\n",
    "    \n",
    "    return(X_up, y_up)\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    print(\"\\n=============================\")\n",
    "    print(\"======== DATASET \", i, \" ========\")\n",
    "    print(\"=============================\\n\")\n",
    "    for j, df in enumerate(dataset):\n",
    "        print(\"\\n======== proportion: \", proportions[j], \" ========\")\n",
    "        X = np.array(df[['X1', 'X2']])\n",
    "        y = np.array(df['y'])   \n",
    "        X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=.5, random_state=42)\n",
    "        X_train, y_train = up_sampling(...) #TODO!\n",
    "\n",
    "        model = SVC(gamma=\"auto\")\n",
    "        model.fit(X_train, y_train)\n",
    "        plot_datasets(dataset,model)\n",
    "\n",
    "        evaluate(model, X_val, y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('nglm-env': conda)",
   "language": "python",
   "name": "python37464bitnglmenvcondafb2d26c675db497c954f514d34bc1654"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
