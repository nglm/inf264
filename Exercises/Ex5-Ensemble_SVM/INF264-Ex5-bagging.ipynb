{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap Aggregation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the dataset and store it as a pandas dataframe\n",
    "dataset = pd.read_csv('sonar.all-data',header=None)\n",
    "# Store features in a pandas dataframe X\n",
    "X = dataset.iloc[:,:-1]\n",
    "# Convert X into a numpy array\n",
    "X = X.to_numpy()\n",
    "\n",
    "# Store labels in a numpy array y\n",
    "y = dataset.iloc[:,-1].to_numpy()\n",
    "# Convert it into a array of boolean (True if 'M' and False otherwise)\n",
    "y = (y == 'M')\n",
    "# Convert it into a array of int (1 if 'True' and 0 otherwise)\n",
    "y = y.astype(int)\n",
    "\n",
    "print(\"Number of samples: \", X.shape[0])\n",
    "print('Number of features: ', X.shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsample function\n",
    "\n",
    "\n",
    "You can use the function [random.choices()](https://docs.python.org/3/library/random.html#random.choices) to get a subsampling with replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bootstrap_sample(\n",
    "    X,\n",
    "    y,\n",
    "    n_samples=None   # number of samples in the subsampling\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a random subsample from the dataset with replacement\n",
    "    \"\"\"\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging train and predict functions\n",
    "\n",
    "\n",
    "**Note**: in scikit-learn, all supervised estimators implement a ``fit(X, y)`` method and a ``predict(X)`` method with ``X`` being unlabeled observations and  ``y`` being labels. \n",
    "\n",
    "Therefore ``Classifier`` parameter can be any sklearn class implementing a supervised classifier.\n",
    "\n",
    "(See *The problem solved in supervised learning* section in the supervised learning tutorial from [sklearn documentation](https://scikit-learn.org/stable/tutorial/statistical_inference/supervised_learning.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging_train(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    n_clfs,                                  # number of classifier\n",
    "    Classifier = DecisionTreeClassifier,     # Python class of classifier\n",
    "    clfs_args = {},                          # Specific python class of classifier's arguments\n",
    "):\n",
    "    \"\"\"\n",
    "    Bootstrap Aggregation training algorithm\n",
    "    \"\"\"\n",
    "    clfs = []\n",
    "    for i in range(n_clfs):\n",
    "        # -------------------------\n",
    "        # Train a new classifier\n",
    "        # -------------------------\n",
    "        # Take a subsample of X and Y (with replacement)\n",
    "        #TODO!\n",
    "        # Initialize a new Classifier object\n",
    "        #TODO!\n",
    "        # Train this new Classifier object\n",
    "        #TODO!\n",
    "        # Append your trained classifier in your list of classifiers \n",
    "        #TODO!\n",
    "    # Return the list of trained classifiers composing the bagging classifier\n",
    "    return clfs\n",
    "\n",
    "\n",
    "def bagging_predict(\n",
    "    clfs,     # list of classifiers composing the bagging classifier\n",
    "    X\n",
    "):\n",
    "    \"\"\"\n",
    "    Bootstrap Aggregation predict algorithm\n",
    "    \"\"\"\n",
    "    #TODO!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging pipeline using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training different bagging models on the sonar dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TODO!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting and evaluating the best bagging model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('nglm-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "71c2cb666ff353b4e7b5c350d66179fa0af5c84ce239ad9fa105d94543f3ad59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
